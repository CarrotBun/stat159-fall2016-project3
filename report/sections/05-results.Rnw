\section{Results}

<<results, results= 'asis', echo = FALSE>>=
Regression <- c('OLS','Ridge', 'Lasso', 'PCR', 'PLSR')
MSE <- c(ols_MSE, ridge_MSE, lasso_tMSE, pcr_tMSE, pls_mse)
mse_chart <- data.frame(Regression, MSE)
mse_tbl <- xtable(mse_chart,
               caption = 'Test MSE Values for the Regression Techniques',
               digits = 7)

print(mse_tbl, caption.placement = 'top',
      comment = getOption('xtable.comment', FALSE),
      include.rownames = FALSE)
@

In order to figure out which is the best model, we decided to compare the mean squared error (MSE) values and pick the model and method that produced the smallest MSE value. The smaller the MSE, the higher the prediction accuracy of the model. When Looking at the table Test MSE Values for the Regression Techniques, we found that all the MSEs were very similar with the range being \Sexpr{round(pls_mse-lasso_tMSE, 4)}. Of all the regression methods, we found that the one that produced the smallest MSE is lasso regression, where MSE = \Sexpr{round(lasso_tMSE, 4)}. So, we will use the equation produced via lasso regression in our app in order to help predict admission rates.

\medskip
However, one issue that we ran into when using lasso to predict the coefficients for the full model is that it turns almost all of the variables into 0. This reduces the model to a state where it is not reliable and so we do not want to use this model. Instead, we decided to solve the reliability issue in our app by calculating a model using a smaller subset of schools and used ridge regression to find the coefficents instead. This is because ridge regression gives us the second lowest MSE of all the different regression methods. When using our app, we will first input the school's OPEID in order to get information about the school. Focusing in on the admission rate, our app will randomly choose 20 schools with a smaller admission rate and build a regression model using lasso regression. From this equation, we will predict what our client's new admission rate is using the scaled data for our client's school as the inputs. The output of our model will be an admission rate in terms of scaled data, but in our app, we have a formula that will convert that scaled admission rate into an admission rate that is understandable and comparable with their current admission rate. Additionally, we can select the variables that we want to input and using various variables and various amounts of variables, that will change what our prediction is.

\medskip
To better illustrate how this works, we will walk through an example together. Let's pretend our client is Alabama A\&M University. We input some of attributes into our app to find some schools that are similar to Alabama A\&M and found schools that are similar but have a lower admission rate. Alabama A\&M's admission rate is .56, and through our app, some similar schools with lower admission rates are Villanova University, Chicago State University, Franklin and Marshall and etc. Using the regression model that was creating using the sample of schools that are similar but with a lower admission rate, our model predicts that if Alabama A\&M becomes closer to those other schools in terms of size, percentage of women, percentage of black students, percentage of white students, and the average age when entering college, then it's new admission rate could be .54. This means that the admission rate is lowered by .02, which is pretty reasonable for changing admission rates within a year.

\medskip
We also tried different combination of variables. For example, when we only used inputs such as age of entry and size, it predicted that our admission rate would be .57, which is actually higher then what our original admission rate was. However, when we used size, percentage of women, percentage of black students, percentage of white students, percentage of Hispanic students, and the average age when entering college, we were able to lower the admission rate to be .52, which is much lower that what we started off with and even lower then the prediction that we previously found. Being able to play with these variables and inputs is important because it helps us to identify the areas and profiles in which there needs to be changes for each school and we can help them to improve their rates by various percentages with ability to focus in on certain areas.
