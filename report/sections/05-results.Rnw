# Results

```{r results= 'asis', echo = FALSE}
Regression <- c('OLS','Ridge', 'Lasso', 'PCR', 'PLSR')
MSE <- c(ols_MSE, ridge_MSE, lasso_tMSE, pcr_tMSE, pls_mse)
mse_chart <- data.frame(Regression, MSE)
mse_tbl <- xtable(mse_chart,
               caption = 'Test MSE Values for the Regression Techniques',
               digits = 7)

print(mse_tbl, caption.placement = 'top',
      comment = getOption('xtable.comment', FALSE),
      include.rownames = FALSE)
```
In order to figure out which is the best model, we decided to compare the mean squared error (MSE) values and pick the model and method that produced the smallest MSE value. The smaller the MSE, the higher the prediction accuracy of the model. When Looking at the table Test MSE Values for the Regression Techniques, we found that all the MSEs were very similar with the range being `r pls_mse-lasso_tMSE`. Of all the regression methods, we found that the one that produced the smallest MSE is lasso regression, where MSE = `r lasso_tMSE`. So, we will use the equation produced via lasso regression in our app in order to help predict admission rates.

However, one issue that we ran into when using lasso to predict the coefficients for the full model is that it turns almost all of the variables into 0. This reduces the model to a state where it is not reliable and does not make that much sense to us. While the model given does not make much sense, we still believe that lasso regression will give us the best model because it is able to reduce the MSE the most. We decided to solve the reliability issue in our app by calculating a model using a smaller subset of schools. When using our app, we will first input the school's OPEID in order to get information about the school. Focusing in on the admission rate, our app will randomly choose 20 schools with a smaller admission rate and build a regression model using lasso regression. From this equation, we will predict what our client's new admission rate is using the scaled data for our client's school as the inputs. The output of our model will be an admission rate in terms of scaled data, but in our app, we have a formula tht will convert that scaled admission rate into an admission rate that is understandable and comperable with their current admission rate.

To better illustrate how this works, we will walk through an example together. Let's pretend our client is Alabama A&M University. We input some of attributes into our app to find some schools that are similar to Alabama A&M and found schools that are similar but have a lower admission rate. Alabama A&M's admission rate is .56, and through our app, some similar schools with lower admission rates are Villanova University, Chicago State University, Franklin and Marshall and etc. Using the regression model that was creating using the sample of schools that are similar but with a lower admission rate, our model predicts that if Alabama A&M becomes closer to those other schools in terms of size, percentage of women, percentage of black students, percentage of white students, and the average age when entering college, then it's new admission rate could be .54. This means that the admission rate is lowered by .02, which is pretty reasonable for changing admission rates within a year.

We wanted to see how changing different variables can affect the admission rates in order to see how different variables impact the school. So, we tested a couple of different attributes to see what would happen to the admission rate depending on what variables we included. When we just included size and entry age, our model predicted that the admssion rate would actually be .01 one higher, but by adding more variables, we were able to lower the admission rate. This show that if you change some variables and not the others, our model doesn't always lower your admission rate, if you want there to be change, you must change the entire package or aspect of it.
